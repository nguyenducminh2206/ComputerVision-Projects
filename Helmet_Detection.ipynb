{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnMfVhE+cVDN8+V7pRJxgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenducminh2206/ComputerVision-Projects/blob/main/Helmet_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/THU-MIG/yolov10.git"
      ],
      "metadata": {
        "id": "40NsiAo38_Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov10\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "otzlMnMmsHrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "XiA5C1uVs8jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt"
      ],
      "metadata": {
        "id": "npSCERZptHeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLOv10"
      ],
      "metadata": {
        "id": "gZv7D-4HtdmM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'yolov10n.pt'\n",
        "model = YOLOv10(model_path)"
      ],
      "metadata": {
        "id": "qw715dO8tipq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown '1tr9PSRRdlC2pNir7jsYugpSMG-7v32VJ' -O './images/'"
      ],
      "metadata": {
        "id": "eX-R0Ra7tniN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/yolov10/images/HCMC_Street.jpg'\n",
        "result = model(source=img_path)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf_kHGi-t-JV",
        "outputId": "43ba6df5-4b09-4ab8-c8e6-1affd18d75d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/yolov10/images/HCMC_Street.jpg: 448x640 11 persons, 2 bicycles, 1 car, 2 motorcycles, 70.7ms\n",
            "Speed: 14.6ms preprocess, 70.7ms inference, 3.7ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.save('./images/HCMC_Street_predict.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bYC0Tlc3uJTV",
        "outputId": "e38da3c8-dc09-4055-9482-0a31db1d3243"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./images/HCMC_Street_predict.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown '1twdtZEfcw4ghSZIiPDypJurZnNXzMO7R'"
      ],
      "metadata": {
        "id": "Zkn-3UwOuiUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir safety_helmet_dataset"
      ],
      "metadata": {
        "id": "x9977VDGuq97"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/yolov10/Safety_Helmet_Dataset.zip' -d '/content/yolov10/safety_helmet_dataset'"
      ],
      "metadata": {
        "id": "BbiKt8NYuya3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_path = '/content/yolov10/safety_helmet_dataset/data.yaml'\n",
        "epochs = 30\n",
        "img_size = 640\n",
        "batch_size = 16\n",
        "\n",
        "model.train(data=yaml_path,\n",
        "            epochs=epochs,\n",
        "            imgsz=img_size)"
      ],
      "metadata": {
        "id": "PWtOVhiWu_P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_path = '/content/yolov10/runs/detect/train/weights/best.pt'\n",
        "model = YOLOv10(trained_model_path)\n",
        "\n",
        "model.val(data=yaml_path,\n",
        "          imgsz=img_size,\n",
        "          split='test')"
      ],
      "metadata": {
        "id": "M3wew81XyuNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test trained YOLOv10 model"
      ],
      "metadata": {
        "id": "ySdvACI6zaaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "T3_guaD1zZ70"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'yolov10n.pt'\n",
        "model = YOLOv10(model_path)"
      ],
      "metadata": {
        "id": "7HB8EodGzyOn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_dir = '/content/yolov10/safety_helmet_dataset/test/images'"
      ],
      "metadata": {
        "id": "Zife7cS-0DNK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = [os.path.join(test_img_dir, img) for img in os.listdir(test_img_dir) if img.endswith('.jpg') or img.endswith('.png')]"
      ],
      "metadata": {
        "id": "wZkrO0Xe1B9m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 1 or 2 images to test\n",
        "selected_test_images = test_images[:2]  # Adjust the number of images as needed\n",
        "\n",
        "# Run inference on selected test images\n",
        "for img_path in selected_test_images:\n",
        "    # Perform inference\n",
        "    results = model.predict(img_path)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Results for {img_path}:\")\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            # Extract bounding box coordinates, confidence, and class_id\n",
        "            coords = box.xyxy[0]  # Extract the coordinates from the tensor\n",
        "            x1, y1, x2, y2 = coords[0], coords[1], coords[2], coords[3]\n",
        "            confidence = box.conf[0].item()  # Extract confidence as a Python float\n",
        "            class_id = box.cls.item()  # Extract class_id as a Python int\n",
        "\n",
        "            # Print the results\n",
        "            print(f\"Class ID: {class_id}, Confidence: {confidence:.2f}, Bounding Box: ({x1:.2f}, {y1:.2f}, {x2:.2f}, {y2:.2f})\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU6WG2Ee2Nh1",
        "outputId": "38ca6fed-c035-44ea-a4b5-8193c4f8e785"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/yolov10/safety_helmet_dataset/test/images/person-509-_jpg.rf.8f332fcdb0e9cb2ecc334fe017939499.jpg: 640x640 1 person, 16.4ms\n",
            "Speed: 7.3ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results for /content/yolov10/safety_helmet_dataset/test/images/person-509-_jpg.rf.8f332fcdb0e9cb2ecc334fe017939499.jpg:\n",
            "Class ID: 0.0, Confidence: 0.80, Bounding Box: (0.41, 79.69, 238.11, 415.59)\n",
            "\n",
            "\n",
            "\n",
            "image 1/1 /content/yolov10/safety_helmet_dataset/test/images/person-497-_jpg.rf.829207af90f0a48dd92accaf81cd84aa.jpg: 640x640 2 persons, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results for /content/yolov10/safety_helmet_dataset/test/images/person-497-_jpg.rf.829207af90f0a48dd92accaf81cd84aa.jpg:\n",
            "Class ID: 0.0, Confidence: 0.92, Bounding Box: (0.18, 31.10, 224.70, 415.37)\n",
            "Class ID: 0.0, Confidence: 0.33, Bounding Box: (0.09, 25.00, 39.67, 159.11)\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}